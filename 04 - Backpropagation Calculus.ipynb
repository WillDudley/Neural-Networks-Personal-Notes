{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document assumes having seen 3Blue1Brown's video series on Neural Networks, specifically video 4, found here: https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $L$ be the index of the output layer of a neural network, and $y$ our desired output (AKA true_label). Then, if we use a simple quadratic cost function as in the video, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Cost}=C=(a^{(L)}-y)^2 .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where, as usual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a^{(L)} = \\sigma (z^{(L)}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z^{(L)} = w^{(L)}a^{(L-1)}+b^{(L)},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $w$ and $b$ as our respective biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be seen as a recursive network, and we are interested in how $C$ changes as $w^{(L)},b^{(L)},a^{(L-1)}$ change (ie. $C$'s sensitivity to the aformentioned parameters). We see in the video that this respectively equals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial w^{(L)}}=\\dfrac{\\partial z^{(L)}}{\\partial w^{(L)}}\\dfrac{\\partial a^{(L)}}{\\partial z^{(L)}}\\dfrac{\\partial C}{\\partial a^{(L)}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial b^{(L)}}=\\dfrac{\\partial z^{(L)}}{\\partial b^{(L)}}\\dfrac{\\partial a^{(L)}}{\\partial z^{(L)}}\\dfrac{\\partial C}{\\partial a^{(L)}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial a^{(L-1)}}=\\dfrac{\\partial z^{(L)}}{\\partial a^{(L-1)}}\\dfrac{\\partial a^{(L)}}{\\partial z^{(L)}}\\dfrac{\\partial C}{\\partial a^{(L)}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial a^{(L)}}{\\partial z^{(L)}} = \\sigma ' (z^{(L)}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial a^{(L)}} = C'(a^{(L)}) = 2(a^{(L)} - y).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first depends on the activation function, and the second depends on the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had more than one neuron in the layer, in order to get the overall cost function we'd just take the average of the sum of the cost functions for each neuron (see around 8:00 in the video).\n",
    "\n",
    "The other thing that changes is the sensitivity to the previous layer's activation function (as it affects both neurons), which becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial a_k^{(L-1)}} = \\sum_{j=0}^{n_L-1} \\dfrac{\\partial z_j^{(L)}}{\\partial a_k^{(L-1)}}\\dfrac{\\partial a_j^{(L)}}{\\partial z_j^{(L)}}\\dfrac{\\partial C}{\\partial a_j^{(L)}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, as seen above, one needs to now keep track of subscripts which represent which neuron of the layer $L$ we're actually referring to. Intuitively, $z_j^{(L)}$ now equals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z_j^{(L)} = \\left( \\sum_{k=0}^n w_{jk}^{(L)}a_k^{(L-1)} \\right) + b_j^{(L)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial w_{jk}^{(L)}}=\\dfrac{\\partial z_j^{(L)}}{\\partial w_{jk}^{(L)}}\\dfrac{\\partial a_j^{(L)}}{\\partial z_j^{(L)}}\\dfrac{\\partial C}{\\partial a_j^{(L)}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial b_j^{(L)}}=\\dfrac{\\partial z_j^{(L)}}{\\partial b_j^{(L)}}\\dfrac{\\partial a_j^{(L)}}{\\partial z_j^{(L)}}\\dfrac{\\partial C}{\\partial a_j^{(L)}},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial a_k^{(L-1)}} = \\sum_{j=0}^{n_L-1} \\dfrac{\\partial z_j^{(L)}}{\\partial a_k^{(L-1)}}\\dfrac{\\partial a_j^{(L)}}{\\partial z_j^{(L)}}\\dfrac{\\partial C}{\\partial a_j^{(L)}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial w_{jk}^{(L)}}=\\dfrac{\\partial z_j^{(L)}}{\\partial w_{jk}^{(L)}} \\sigma ' (z_j^{(L)}) C'(a_j^{(L)}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial b_j^{(L)}}=\\dfrac{\\partial z_j^{(L)}}{\\partial b_j^{(L)}}\\sigma ' (z_j^{(L)}) C'(a_j^{(L)}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\dfrac{\\partial C}{\\partial a_k^{(L-1)}} = \\sum_{j=0}^{n_L-1} \\dfrac{\\partial z_j^{(L)}}{\\partial a_k^{(L-1)}} \\sigma ' (z_j^{(L)}) C'(a_j^{(L)}).$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
